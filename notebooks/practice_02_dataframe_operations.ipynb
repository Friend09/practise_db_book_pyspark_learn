{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d580e40a",
   "metadata": {},
   "source": [
    "# DataFrame Operations - Practice Notebook\n",
    "\n",
    "This notebook focuses on **Untyped Dataset Operations** (DataFrame operations) as covered in the [Spark SQL Getting Started Guide](https://spark.apache.org/docs/latest/sql-getting-started.html).\n",
    "\n",
    "## Learning Objectives\n",
    "- Master DataFrame transformations and actions\n",
    "- Understand lazy evaluation in Spark\n",
    "- Practice column operations and expressions\n",
    "- Work with different data types and functions\n",
    "\n",
    "## Sections\n",
    "1. **Setup and Data Preparation**\n",
    "2. **Column Selection and Expressions**\n",
    "3. **Filtering and Conditional Operations**\n",
    "4. **Transformations vs Actions**\n",
    "5. **Working with Functions**\n",
    "6. **Practice Exercises**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad62283",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/13 12:25:24 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+---------+------+----------+\n",
      "|   name|age|job_title|salary| hire_date|\n",
      "+-------+---+---------+------+----------+\n",
      "|  Alice| 25| Engineer| 75000|2020-01-15|\n",
      "|    Bob| 30|  Manager| 85000|2019-03-20|\n",
      "|Charlie| 35| Engineer| 80000|2018-06-10|\n",
      "|  Diana| 28|  Analyst| 65000|2021-02-28|\n",
      "|    Eve| 32|  Manager| 90000|2017-11-05|\n",
      "|  Frank| 29| Engineer| 78000|2020-09-12|\n",
      "+-------+---+---------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder.appName(\"DataFrame Operations\").getOrCreate()\n",
    "\n",
    "data = [\n",
    "    (\"Alice\", 25, \"Engineer\", 75000, \"2020-01-15\"),\n",
    "    (\"Bob\", 30, \"Manager\", 85000, \"2019-03-20\"),\n",
    "    (\"Charlie\", 35, \"Engineer\", 80000, \"2018-06-10\"),\n",
    "    (\"Diana\", 28, \"Analyst\", 65000, \"2021-02-28\"),\n",
    "    (\"Eve\", 32, \"Manager\", 90000, \"2017-11-05\"),\n",
    "    (\"Frank\", 29, \"Engineer\", 78000, \"2020-09-12\")\n",
    "]\n",
    "\n",
    "columns = [\"name\", \"age\", \"job_title\", \"salary\", \"hire_date\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df1f8b2",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 1. Column Selection and Expressions\n",
    "\n",
    "Learn different ways to select and manipulate columns in DataFrames.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "765e47f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|   name|\n",
      "+-------+\n",
      "|  Alice|\n",
      "|    Bob|\n",
      "|Charlie|\n",
      "|  Diana|\n",
      "|    Eve|\n",
      "|  Frank|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7fefe6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   name|age|\n",
      "+-------+---+\n",
      "|  Alice| 25|\n",
      "|    Bob| 30|\n",
      "|Charlie| 35|\n",
      "|  Diana| 28|\n",
      "|    Eve| 32|\n",
      "|  Frank| 29|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"name\", \"age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "627f0916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   name|age|\n",
      "+-------+---+\n",
      "|  Alice| 25|\n",
      "|    Bob| 30|\n",
      "|Charlie| 35|\n",
      "|  Diana| 28|\n",
      "|    Eve| 32|\n",
      "|  Frank| 29|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.name, df.age).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3fffed9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   name|age|\n",
      "+-------+---+\n",
      "|  Alice| 25|\n",
      "|    Bob| 30|\n",
      "|Charlie| 35|\n",
      "|  Diana| 28|\n",
      "|    Eve| 32|\n",
      "|  Frank| 29|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df[\"name\"], df[\"age\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "58952095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+---------+------+----------+\n",
      "|   name|age|job_title|salary| hire_date|\n",
      "+-------+---+---------+------+----------+\n",
      "|  Alice| 25| Engineer| 75000|2020-01-15|\n",
      "|    Bob| 30|  Manager| 85000|2019-03-20|\n",
      "|Charlie| 35| Engineer| 80000|2018-06-10|\n",
      "|  Diana| 28|  Analyst| 65000|2021-02-28|\n",
      "|    Eve| 32|  Manager| 90000|2017-11-05|\n",
      "|  Frank| 29| Engineer| 78000|2020-09-12|\n",
      "+-------+---+---------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"*\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef31cfa",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2. Filtering and Conditional Operations\n",
    "\n",
    "Practice different filtering techniques and conditional logic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "69ef061d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+---------+------+----------+\n",
      "|   name|age|job_title|salary| hire_date|\n",
      "+-------+---+---------+------+----------+\n",
      "|  Alice| 25| Engineer| 75000|2020-01-15|\n",
      "|    Bob| 30|  Manager| 85000|2019-03-20|\n",
      "|Charlie| 35| Engineer| 80000|2018-06-10|\n",
      "|  Diana| 28|  Analyst| 65000|2021-02-28|\n",
      "|    Eve| 32|  Manager| 90000|2017-11-05|\n",
      "|  Frank| 29| Engineer| 78000|2020-09-12|\n",
      "+-------+---+---------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "14e8bc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+---------+------+----------+\n",
      "|   name|age|job_title|salary| hire_date|\n",
      "+-------+---+---------+------+----------+\n",
      "|Charlie| 35| Engineer| 80000|2018-06-10|\n",
      "|    Eve| 32|  Manager| 90000|2017-11-05|\n",
      "+-------+---+---------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df[\"age\"]>30).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "09da1f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+---------+------+----------+\n",
      "|   name|age|job_title|salary| hire_date|\n",
      "+-------+---+---------+------+----------+\n",
      "|  Alice| 25| Engineer| 75000|2020-01-15|\n",
      "|Charlie| 35| Engineer| 80000|2018-06-10|\n",
      "|  Frank| 29| Engineer| 78000|2020-09-12|\n",
      "+-------+---+---------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df[\"job_title\"]==\"Engineer\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "02d70c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+---------+------+----------+\n",
      "|   name|age|job_title|salary| hire_date|\n",
      "+-------+---+---------+------+----------+\n",
      "|    Bob| 30|  Manager| 85000|2019-03-20|\n",
      "|Charlie| 35| Engineer| 80000|2018-06-10|\n",
      "|    Eve| 32|  Manager| 90000|2017-11-05|\n",
      "|  Frank| 29| Engineer| 78000|2020-09-12|\n",
      "+-------+---+---------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mask1 = df[\"age\"]>28\n",
    "mask2 = df[\"salary\"]>75000\n",
    "\n",
    "df.filter(mask1 & mask2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "49afda2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+---------+------+----------+\n",
      "|   name|age|job_title|salary| hire_date|\n",
      "+-------+---+---------+------+----------+\n",
      "|  Alice| 25| Engineer| 75000|2020-01-15|\n",
      "|Charlie| 35| Engineer| 80000|2018-06-10|\n",
      "|    Eve| 32|  Manager| 90000|2017-11-05|\n",
      "|  Frank| 29| Engineer| 78000|2020-09-12|\n",
      "+-------+---+---------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mask1 = df[\"job_title\"] == \"Engineer\"\n",
    "mask2 = df[\"salary\"] > 85000\n",
    "\n",
    "df.filter(mask1 | mask2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ec0e9fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+---------+------+----------+\n",
      "|   name|age|job_title|salary| hire_date|\n",
      "+-------+---+---------+------+----------+\n",
      "|Charlie| 35| Engineer| 80000|2018-06-10|\n",
      "|  Diana| 28|  Analyst| 65000|2021-02-28|\n",
      "|  Frank| 29| Engineer| 78000|2020-09-12|\n",
      "+-------+---+---------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df[\"name\"].contains(\"a\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "10fe0564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+---------+------+----------+\n",
      "|   name|age|job_title|salary| hire_date|\n",
      "+-------+---+---------+------+----------+\n",
      "|  Alice| 25| Engineer| 75000|2020-01-15|\n",
      "|    Bob| 30|  Manager| 85000|2019-03-20|\n",
      "|Charlie| 35| Engineer| 80000|2018-06-10|\n",
      "|    Eve| 32|  Manager| 90000|2017-11-05|\n",
      "|  Frank| 29| Engineer| 78000|2020-09-12|\n",
      "+-------+---+---------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df[\"job_title\"].isin([\"Engineer\", \"Manager\"])).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2d0755",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. Transformations vs Actions\n",
    "\n",
    "Understanding the difference between lazy transformations and actions that trigger execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "dd9af300",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df.filter(df[\"age\"]>25)\n",
    "selected_df = filtered_df.select(\"name\", \"age\", \"salary\")\n",
    "sorted_df = selected_df.orderBy(\"salary\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7b9b81b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.classic.dataframe.DataFrame"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sorted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ebdba420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+\n",
      "|   name|age|salary|\n",
      "+-------+---+------+\n",
      "|    Eve| 32| 90000|\n",
      "|    Bob| 30| 85000|\n",
      "|Charlie| 35| 80000|\n",
      "|  Frank| 29| 78000|\n",
      "|  Diana| 28| 65000|\n",
      "+-------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sorted_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "145da424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f22c690c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(name='Eve', age=32, salary=90000)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collected_data = sorted_df.collect()\n",
    "type(collected_data)\n",
    "collected_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "98d8b34a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='Eve', age=32, salary=90000),\n",
       " Row(name='Bob', age=30, salary=85000),\n",
       " Row(name='Charlie', age=35, salary=80000),\n",
       " Row(name='Frank', age=29, salary=78000),\n",
       " Row(name='Diana', age=28, salary=65000)]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collected_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "181042dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(name='Eve', age=32, salary=90000)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "318d7418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='Eve', age=32, salary=90000), Row(name='Bob', age=30, salary=85000)]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4ef827e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+---------+------+----------+\n",
      "| name|age|job_title|salary| hire_date|\n",
      "+-----+---+---------+------+----------+\n",
      "|Alice| 25| Engineer| 75000|2020-01-15|\n",
      "+-----+---+---------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.limit(1).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec1cc31",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. Working with Built-in Functions\n",
    "\n",
    "Explore Spark's built-in functions for data manipulation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "248ed12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STRING FUNCTIONS ===\n",
      "+-------+----------+----------+-----------+-------------+\n",
      "|   name|name_upper|name_lower|name_length|first_3_chars|\n",
      "+-------+----------+----------+-----------+-------------+\n",
      "|  Alice|     ALICE|     alice|          5|          Ali|\n",
      "|    Bob|       BOB|       bob|          3|          Bob|\n",
      "|Charlie|   CHARLIE|   charlie|          7|          Cha|\n",
      "|  Diana|     DIANA|     diana|          5|          Dia|\n",
      "|    Eve|       EVE|       eve|          3|          Eve|\n",
      "|  Frank|     FRANK|     frank|          5|          Fra|\n",
      "+-------+----------+----------+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=== STRING FUNCTIONS ===\")\n",
    "df.select(\n",
    "    df[\"name\"],\n",
    "    F.upper(df[\"name\"]).alias(\"name_upper\"),\n",
    "    F.lower(df[\"name\"]).alias(\"name_lower\"),\n",
    "    F.length(df[\"name\"]).alias(\"name_length\"),\n",
    "    F.substring(df[\"name\"],1,3).alias(\"first_3_chars\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "778f932b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MATHEMATICAL FUNCTIONS ===\n",
      "+-------+------+--------------+-----------------+----------------+\n",
      "|   name|salary|monthly_salary|         sqrt_age|age_diff_from_30|\n",
      "+-------+------+--------------+-----------------+----------------+\n",
      "|  Alice| 75000|        6250.0|              5.0|               5|\n",
      "|    Bob| 85000|       7083.33|5.477225575051661|               0|\n",
      "|Charlie| 80000|       6666.67|5.916079783099616|               5|\n",
      "|  Diana| 65000|       5416.67|5.291502622129181|               2|\n",
      "|    Eve| 90000|        7500.0|5.656854249492381|               2|\n",
      "|  Frank| 78000|        6500.0|5.385164807134504|               1|\n",
      "+-------+------+--------------+-----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== MATHEMATICAL FUNCTIONS ===\")\n",
    "df.select(\n",
    "    df[\"name\"],\n",
    "    df[\"salary\"],\n",
    "    F.round(df[\"salary\"] / 12, 2).alias(\"monthly_salary\"),\n",
    "    F.sqrt(df[\"age\"]).alias(\"sqrt_age\"),\n",
    "    F.abs(df[\"age\"] - 30).alias(\"age_diff_from_30\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c78df2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+---------+------+----------+\n",
      "| name|age|job_title|salary| hire_date|\n",
      "+-----+---+---------+------+----------+\n",
      "|Alice| 25| Engineer| 75000|2020-01-15|\n",
      "+-----+---+---------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.limit(1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "22eda147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DATE FUNCTIONS ===\n",
      "+-------+----------+---------+----------+---------------+\n",
      "|   name| hire_date|hire_year|hire_month|days_since_hire|\n",
      "+-------+----------+---------+----------+---------------+\n",
      "|  Alice|2020-01-15|     2020|         1|           2006|\n",
      "|    Bob|2019-03-20|     2019|         3|           2307|\n",
      "|Charlie|2018-06-10|     2018|         6|           2590|\n",
      "|  Diana|2021-02-28|     2021|         2|           1596|\n",
      "|    Eve|2017-11-05|     2017|        11|           2807|\n",
      "|  Frank|2020-09-12|     2020|         9|           1765|\n",
      "+-------+----------+---------+----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Date functions (convert string to date first)\n",
    "print(\"\\n=== DATE FUNCTIONS ===\")\n",
    "df_with_date = df.withColumn(\"hire_date\", F.to_date(df[\"hire_date\"], \"yyyy-MM-dd\"))\n",
    "\n",
    "df_with_date.select(\n",
    "    df[\"name\"],\n",
    "    df_with_date[\"hire_date\"],\n",
    "    F.year(df_with_date[\"hire_date\"]).alias(\"hire_year\"),\n",
    "    F.month(df_with_date[\"hire_date\"]).alias(\"hire_month\"),\n",
    "    F.datediff(F.current_date(), df_with_date[\"hire_date\"]).alias(\"days_since_hire\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd822ca",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5. Advanced DataFrame Operations\n",
    "\n",
    "Explore more advanced operations like grouping, aggregations, and window functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e0cac125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+---------+------+----------+\n",
      "|   name|age|job_title|salary| hire_date|\n",
      "+-------+---+---------+------+----------+\n",
      "|  Alice| 25| Engineer| 75000|2020-01-15|\n",
      "|    Bob| 30|  Manager| 85000|2019-03-20|\n",
      "|Charlie| 35| Engineer| 80000|2018-06-10|\n",
      "|  Diana| 28|  Analyst| 65000|2021-02-28|\n",
      "|    Eve| 32|  Manager| 90000|2017-11-05|\n",
      "|  Frank| 29| Engineer| 78000|2020-09-12|\n",
      "+-------+---+---------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "633b3949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GROUPING AND AGGREGATION ===\n",
      "1. Group by job title and calculate statistics:\n",
      "+---------+-----+-----------------+-------+-------+\n",
      "|job_title|count|       avg_salary|min_age|max_age|\n",
      "+---------+-----+-----------------+-------+-------+\n",
      "| Engineer|    3|77666.66666666667|     25|     35|\n",
      "|  Manager|    2|          87500.0|     30|     32|\n",
      "|  Analyst|    1|          65000.0|     28|     28|\n",
      "+---------+-----+-----------------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=== GROUPING AND AGGREGATION ===\")\n",
    "print(\"1. Group by job title and calculate statistics:\")\n",
    "\n",
    "df.groupBy(\"job_title\").agg(\n",
    "    F.count(\"*\").alias(\"count\"),\n",
    "    F.avg(\"salary\").alias(\"avg_salary\"),\n",
    "    F.min(\"age\").alias(\"min_age\"),\n",
    "    F.max(\"age\").alias(\"max_age\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b870a16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Multiple grouping columns:\n",
      "+---------+-----------+-----+----------+\n",
      "|job_title|  age_group|count|avg_salary|\n",
      "+---------+-----------+-----+----------+\n",
      "|  Analyst|      Young|    1|   65000.0|\n",
      "| Engineer|Experienced|    1|   80000.0|\n",
      "| Engineer|      Young|    2|   76500.0|\n",
      "|  Manager|Experienced|    2|   87500.0|\n",
      "+---------+-----------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n2. Multiple grouping columns:\")\n",
    "\n",
    "(\n",
    "    df\n",
    "    .withColumn(\"age_group\", F.when(df[\"age\"] < 30, \"Young\").otherwise(\"Experienced\"))\n",
    "    .groupBy(\"job_title\", \"age_group\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"count\"),\n",
    "        F.avg(\"salary\").alias(\"avg_salary\")\n",
    "        )\n",
    "    .orderBy(\"job_title\", \"age_group\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6c28fc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== WINDOW FUNCTIONS ===\n",
      "+-------+---------+------+-----------+------------+-----------+\n",
      "|   name|job_title|salary|rank_in_job|overall_rank|prev_salary|\n",
      "+-------+---------+------+-----------+------------+-----------+\n",
      "|  Diana|  Analyst| 65000|          1|           1|       NULL|\n",
      "|  Alice| Engineer| 75000|          1|           2|      65000|\n",
      "|  Frank| Engineer| 78000|          2|           3|      75000|\n",
      "|Charlie| Engineer| 80000|          3|           4|      78000|\n",
      "|    Bob|  Manager| 85000|          1|           5|      80000|\n",
      "|    Eve|  Manager| 90000|          2|           6|      85000|\n",
      "+-------+---------+------+-----------+------------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/13 12:45:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/07/13 12:45:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/07/13 12:45:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/07/13 12:45:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== WINDOW FUNCTIONS ===\")\n",
    "from pyspark.sql.window import  Window\n",
    "\n",
    "window_spec = Window.partitionBy(\"job_title\").orderBy(\"salary\")\n",
    "window_all = Window.orderBy(\"salary\")\n",
    "\n",
    "df.select(\n",
    "    df[\"name\"],\n",
    "    df[\"job_title\"],\n",
    "    df[\"salary\"],\n",
    "    F.row_number().over(window_spec).alias(\"rank_in_job\"),\n",
    "    F.rank().over(window_all).alias(\"overall_rank\"),\n",
    "    F.lag(df[\"salary\"], 1).over(window_all).alias(\"prev_salary\")\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d0a0a62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+---------+------+----------+\n",
      "|   name|age|job_title|salary| hire_date|\n",
      "+-------+---+---------+------+----------+\n",
      "|  Diana| 28|  Analyst| 65000|2021-02-28|\n",
      "|  Alice| 25| Engineer| 75000|2020-01-15|\n",
      "|Charlie| 35| Engineer| 80000|2018-06-10|\n",
      "|  Frank| 29| Engineer| 78000|2020-09-12|\n",
      "|    Bob| 30|  Manager| 85000|2019-03-20|\n",
      "|    Eve| 32|  Manager| 90000|2017-11-05|\n",
      "+-------+---+---------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(\"job_title\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cba9612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1867d09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "536cd843",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 6. Practice Exercises\n",
    "\n",
    "Complete these exercises to test your understanding of DataFrame operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a6dff25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+-----+--------+\n",
      "|product_name|   category|price|quantity|\n",
      "+------------+-----------+-----+--------+\n",
      "|   Product A|Electronics| 1500|      10|\n",
      "|   Product B|   Clothing|  800|      25|\n",
      "|   Product C|Electronics| 2000|       5|\n",
      "|   Product D|      Books|  300|      50|\n",
      "|   Product E|   Clothing| 1200|      15|\n",
      "|   Product F|Electronics| 1800|       8|\n",
      "+------------+-----------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_data = [\n",
    "    (\"Product A\", \"Electronics\", 1500, 10),\n",
    "    (\"Product B\", \"Clothing\", 800, 25),\n",
    "    (\"Product C\", \"Electronics\", 2000, 5),\n",
    "    (\"Product D\", \"Books\", 300, 50),\n",
    "    (\"Product E\", \"Clothing\", 1200, 15),\n",
    "    (\"Product F\", \"Electronics\", 1800, 8)\n",
    "]\n",
    "\n",
    "sales_df = spark.createDataFrame(sales_data, [\"product_name\", \"category\", \"price\", \"quantity\"])\n",
    "sales_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "6ee3e19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise 1: Select product_name and calculate total_value (price * quantity)\n",
      "+------------+-----------+\n",
      "|product_name|total_value|\n",
      "+------------+-----------+\n",
      "|   Product A|      15000|\n",
      "|   Product B|      20000|\n",
      "|   Product C|      10000|\n",
      "|   Product D|      15000|\n",
      "|   Product E|      18000|\n",
      "|   Product F|      14400|\n",
      "+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Exercise 1: Select product_name and calculate total_value (price * quantity)\")\n",
    "# Your code here\n",
    "sales_df.select(\n",
    "    F.col(\"product_name\"),\n",
    "    (F.col(\"price\") * F.col(\"quantity\")).alias(\"total_value\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "783b76d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exercise 2: Filter products with price > 1000\n",
      "+------------+-----------+-----+--------+\n",
      "|product_name|   category|price|quantity|\n",
      "+------------+-----------+-----+--------+\n",
      "|   Product A|Electronics| 1500|      10|\n",
      "|   Product C|Electronics| 2000|       5|\n",
      "|   Product E|   Clothing| 1200|      15|\n",
      "|   Product F|Electronics| 1800|       8|\n",
      "+------------+-----------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nExercise 2: Filter products with price > 1000\")\n",
    "\n",
    "mask1 = sales_df[\"price\"] > 1000\n",
    "sales_df.filter(mask1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "49c3640d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exercise 3: Add a price_category column: 'Expensive' if price > 1500, else 'Affordable'\n",
      "+------------+-----------+-----+--------+--------------+\n",
      "|product_name|   category|price|quantity|price_category|\n",
      "+------------+-----------+-----+--------+--------------+\n",
      "|   Product A|Electronics| 1500|      10|    Affordable|\n",
      "|   Product B|   Clothing|  800|      25|    Affordable|\n",
      "|   Product C|Electronics| 2000|       5|     Expensive|\n",
      "|   Product D|      Books|  300|      50|    Affordable|\n",
      "|   Product E|   Clothing| 1200|      15|    Affordable|\n",
      "|   Product F|Electronics| 1800|       8|     Expensive|\n",
      "+------------+-----------+-----+--------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nExercise 3: Add a price_category column: 'Expensive' if price > 1500, else 'Affordable'\")\n",
    "\n",
    "sales_df.withColumn(\n",
    "    \"price_category\",\n",
    "    F.when(sales_df[\"price\"]>1500, \"Expensive\").otherwise(\"Affordable\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "eeb6348c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exercise 4: Group by category and calculate average price and total quantity\n",
      "+-----------+------------------+--------------+\n",
      "|   category|       total_price|total_quantity|\n",
      "+-----------+------------------+--------------+\n",
      "|Electronics|1766.6666666666667|             3|\n",
      "|   Clothing|            1000.0|             2|\n",
      "|      Books|             300.0|             1|\n",
      "+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nExercise 4: Group by category and calculate average price and total quantity\")\n",
    "# Your code here\n",
    "sales_df.groupby(\"category\").agg(\n",
    "    F.avg(\"price\").alias(\"total_price\"),\n",
    "    F.count(\"quantity\").alias(\"total_quantity\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "e3d55d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exercise 5: Find the most expensive product in each category\n",
      "+------------+-----------+-----+-----------------+\n",
      "|product_name|   category|price|expensive_product|\n",
      "+------------+-----------+-----+-----------------+\n",
      "|   Product D|      Books|  300|                1|\n",
      "|   Product B|   Clothing|  800|                1|\n",
      "|   Product E|   Clothing| 1200|                2|\n",
      "|   Product A|Electronics| 1500|                1|\n",
      "|   Product F|Electronics| 1800|                2|\n",
      "|   Product C|Electronics| 2000|                3|\n",
      "+------------+-----------+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nExercise 5: Find the most expensive product in each category\")\n",
    "window_spec = Window.partitionBy(\"category\").orderBy(\"price\")\n",
    "\n",
    "sales_df.select(\n",
    "    sales_df[\"product_name\"],\n",
    "    sales_df[\"category\"],\n",
    "    sales_df[\"price\"],\n",
    "    F.rank().over(window_spec).alias(\"expensive_product\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4198295e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import window\n",
    "\n",
    "window_spec = Window.partitionBy(\"job_title\").orderBy(\"salary\")\n",
    "window_all = Window.orderBy(\"salary\")\n",
    "\n",
    "df.select(\n",
    "    df[\"name\"],\n",
    "    df[\"job_title\"],\n",
    "    df[\"salary\"],\n",
    "    F.row_number().over(window_spec).alias(\"rank_in_job\"),\n",
    "    F.rank().over(window_all).alias(\"overall_rank\"),\n",
    "    F.lag(df[\"salary\"], 1).over(window_all).alias(\"prev_salary\")\n",
    ").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
