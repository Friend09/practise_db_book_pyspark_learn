{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b3c938c",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Running SQL Queries - Practice Notebook\n",
    "\n",
    "This notebook covers **Running SQL Queries Programmatically** and **Global Temporary Views** from the [Spark SQL Getting Started Guide](https://spark.apache.org/docs/latest/sql-getting-started.html).\n",
    "\n",
    "## Learning Objectives\n",
    "- Register DataFrames as temporary views\n",
    "- Execute SQL queries using spark.sql()\n",
    "- Understand the difference between temporary and global temporary views\n",
    "- Compare DataFrame API vs SQL syntax\n",
    "- Practice complex SQL queries\n",
    "\n",
    "## Sections\n",
    "1. **Setup and Data Preparation**\n",
    "2. **Creating Temporary Views**\n",
    "3. **Running SQL Queries**\n",
    "4. **Global Temporary Views**\n",
    "5. **DataFrame API vs SQL Comparison**\n",
    "6. **Complex SQL Queries**\n",
    "7. **Practice Exercises**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f9b71a",
   "metadata": {},
   "source": [
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark = SparkSession.builder.appName(\"SQL Queries Practise\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ad3b82c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample datasets\n",
    "employees_data = [\n",
    "    (1, \"Alice\", \"Engineering\", 75000, \"2020-01-15\"),\n",
    "    (2, \"Bob\", \"Sales\", 65000, \"2019-03-20\"),\n",
    "    (3, \"Charlie\", \"Engineering\", 80000, \"2018-06-10\"),\n",
    "    (4, \"Diana\", \"Marketing\", 70000, \"2021-02-28\"),\n",
    "    (5, \"Eve\", \"Sales\", 68000, \"2017-11-05\"),\n",
    "    (6, \"Frank\", \"Engineering\", 82000, \"2020-09-12\")\n",
    "]\n",
    "\n",
    "departments_data = [\n",
    "    (\"Engineering\", \"Tech\", \"Alice Johnson\"),\n",
    "    (\"Sales\", \"Business\", \"Bob Smith\"),\n",
    "    (\"Marketing\", \"Business\", \"Charlie Brown\"),\n",
    "    (\"HR\", \"Support\", \"Diana Prince\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb14882b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employees DataFrame:\n",
      "+---+-------+-----------+------+----------+\n",
      "| id|   name| department|salary| hire_date|\n",
      "+---+-------+-----------+------+----------+\n",
      "|  1|  Alice|Engineering| 75000|2020-01-15|\n",
      "|  2|    Bob|      Sales| 65000|2019-03-20|\n",
      "|  3|Charlie|Engineering| 80000|2018-06-10|\n",
      "|  4|  Diana|  Marketing| 70000|2021-02-28|\n",
      "|  5|    Eve|      Sales| 68000|2017-11-05|\n",
      "|  6|  Frank|Engineering| 82000|2020-09-12|\n",
      "+---+-------+-----------+------+----------+\n",
      "\n",
      "Departments DataFrame:\n",
      "+-----------+--------+-------------+\n",
      "|  dept_name|division|      manager|\n",
      "+-----------+--------+-------------+\n",
      "|Engineering|    Tech|Alice Johnson|\n",
      "|      Sales|Business|    Bob Smith|\n",
      "|  Marketing|Business|Charlie Brown|\n",
      "|         HR| Support| Diana Prince|\n",
      "+-----------+--------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees_df = spark.createDataFrame(employees_data, [\"id\", \"name\", \"department\", \"salary\", \"hire_date\"])\n",
    "departments_df = spark.createDataFrame(departments_data, [\"dept_name\", \"division\", \"manager\"])\n",
    "\n",
    "print(\"Employees DataFrame:\")\n",
    "employees_df.show()\n",
    "\n",
    "print(\"Departments DataFrame:\")\n",
    "departments_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68033a7b",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 1. Creating Temporary Views\n",
    "\n",
    "To run SQL queries on DataFrames, we first need to register them as temporary views.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temp view created succesfully!\n",
      "\n",
      "Current temporary views:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Table(name='departments', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True),\n",
       " Table(name='employees', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employees_df.createOrReplaceTempView(\"employees\")\n",
    "departments_df.createOrReplaceTempView(\"departments\")\n",
    "\n",
    "print(\"Temp view created succesfully!\")\n",
    "print(\"\\nCurrent temporary views:\")\n",
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27526d7",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2. Running Basic SQL Queries\n",
    "\n",
    "Now we can run SQL queries using the `spark.sql()` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5a00ce75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----------+------+----------+\n",
      "| id|   name| department|salary| hire_date|\n",
      "+---+-------+-----------+------+----------+\n",
      "|  1|  Alice|Engineering| 75000|2020-01-15|\n",
      "|  2|    Bob|      Sales| 65000|2019-03-20|\n",
      "|  3|Charlie|Engineering| 80000|2018-06-10|\n",
      "|  4|  Diana|  Marketing| 70000|2021-02-28|\n",
      "|  5|    Eve|      Sales| 68000|2017-11-05|\n",
      "|  6|  Frank|Engineering| 82000|2020-09-12|\n",
      "+---+-------+-----------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "33aca527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='departments', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True),\n",
       " Table(name='employees', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Select all employees:\n",
      "+---+-------+-----------+------+----------+\n",
      "| id|   name| department|salary| hire_date|\n",
      "+---+-------+-----------+------+----------+\n",
      "|  1|  Alice|Engineering| 75000|2020-01-15|\n",
      "|  2|    Bob|      Sales| 65000|2019-03-20|\n",
      "|  3|Charlie|Engineering| 80000|2018-06-10|\n",
      "|  4|  Diana|  Marketing| 70000|2021-02-28|\n",
      "|  5|    Eve|      Sales| 68000|2017-11-05|\n",
      "|  6|  Frank|Engineering| 82000|2020-09-12|\n",
      "+---+-------+-----------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"1. Select all employees:\")\n",
    "spark.sql(\"SELECT * FROM employees\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "db334aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Select specific columns:\n",
      "+-----------+-------------+\n",
      "|  dept_name|      manager|\n",
      "+-----------+-------------+\n",
      "|Engineering|Alice Johnson|\n",
      "|      Sales|    Bob Smith|\n",
      "|  Marketing|Charlie Brown|\n",
      "|         HR| Diana Prince|\n",
      "+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n2. Select specific columns:\")\n",
    "spark.sql(\"SELECT dept_name, manager FROM departments\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a4b5a2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+-------------+\n",
      "|  dept_name|division|      manager|\n",
      "+-----------+--------+-------------+\n",
      "|Engineering|    Tech|Alice Johnson|\n",
      "|      Sales|Business|    Bob Smith|\n",
      "|  Marketing|Business|Charlie Brown|\n",
      "|         HR| Support| Diana Prince|\n",
      "+-----------+--------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "departments_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "75e16071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Filter with WHERE clause:\n",
      "+---+-------+-----------+------+----------+\n",
      "| id|   name| department|salary| hire_date|\n",
      "+---+-------+-----------+------+----------+\n",
      "|  1|  Alice|Engineering| 75000|2020-01-15|\n",
      "|  3|Charlie|Engineering| 80000|2018-06-10|\n",
      "|  6|  Frank|Engineering| 82000|2020-09-12|\n",
      "+---+-------+-----------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n3. Filter with WHERE clause:\")\n",
    "spark.sql(\"SELECT * FROM employees WHERE salary > 70000\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7ca5c835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----------+------+----------+\n",
      "| id|   name| department|salary| hire_date|\n",
      "+---+-------+-----------+------+----------+\n",
      "|  1|  Alice|Engineering| 75000|2020-01-15|\n",
      "|  3|Charlie|Engineering| 80000|2018-06-10|\n",
      "|  6|  Frank|Engineering| 82000|2020-09-12|\n",
      "+---+-------+-----------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees_df.filter(employees_df[\"salary\"]>70000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "693a80f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Order by salary:\n",
      "+---+-------+-----------+------+----------+\n",
      "| id|   name| department|salary| hire_date|\n",
      "+---+-------+-----------+------+----------+\n",
      "|  2|    Bob|      Sales| 65000|2019-03-20|\n",
      "|  5|    Eve|      Sales| 68000|2017-11-05|\n",
      "|  4|  Diana|  Marketing| 70000|2021-02-28|\n",
      "|  1|  Alice|Engineering| 75000|2020-01-15|\n",
      "|  3|Charlie|Engineering| 80000|2018-06-10|\n",
      "|  6|  Frank|Engineering| 82000|2020-09-12|\n",
      "+---+-------+-----------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n4. Order by salary:\")\n",
    "spark.sql(\"SELECT * FROM employees ORDER BY salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "08868b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. Count employees by department:\n",
      "+-----------+--------------+\n",
      "| department|employee_count|\n",
      "+-----------+--------------+\n",
      "|Engineering|             3|\n",
      "|      Sales|             2|\n",
      "|  Marketing|             1|\n",
      "+-----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n5. Count employees by department:\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT department, count(*) AS employee_count\n",
    "FROM employees\n",
    "GROUP BY department\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7730ca5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+\n",
      "| department|empoyee_count|\n",
      "+-----------+-------------+\n",
      "|Engineering|            3|\n",
      "|      Sales|            2|\n",
      "|  Marketing|            1|\n",
      "+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees_df.groupBy(\"department\").agg(\n",
    "    F.count(\"*\").alias(\"empoyee_count\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250068cd",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. Global Temporary Views\n",
    "\n",
    "Global temporary views are shared across multiple SparkSessions and are kept alive until the Spark application terminates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employees_df.createGlobalTempView(\"global_employees\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT * FROM global_temp.global_employees WHERE department = 'Engineering'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3877494b",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. DataFrame API vs SQL Comparison\n",
    "\n",
    "Let's compare the same operations using DataFrame API and SQL syntax.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EXAMPLE 1: Filter and Select ===\n",
      "DataFrame API:\n"
     ]
    }
   ],
   "source": [
    "print(\"=== EXAMPLE 1: Filter and Select ===\")\n",
    "\n",
    "# DataFrame API\n",
    "print(\"DataFrame API:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b1be0da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL:\n",
      "+-------+-----------+------+\n",
      "|   name| department|salary|\n",
      "+-------+-----------+------+\n",
      "|  Alice|Engineering| 75000|\n",
      "|Charlie|Engineering| 80000|\n",
      "|  Frank|Engineering| 82000|\n",
      "+-------+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"SQL:\")\n",
    "sql_result = spark.sql(\"\"\"\n",
    "    SELECT name, department, salary\n",
    "    FROM employees\n",
    "    WHERE salary > 70000\n",
    "\"\"\")\n",
    "sql_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c2e3a06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "| department|count|\n",
      "+-----------+-----+\n",
      "|Engineering|    3|\n",
      "|      Sales|    2|\n",
      "|  Marketing|    1|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees_df.groupBy('department').agg(\n",
    "    F.count(\"*\").alias(\"count\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396ce9ad",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5. Complex SQL Queries\n",
    "\n",
    "Practice more advanced SQL operations including joins, subqueries, and window functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== JOIN OPERATIONS ===\n",
      "1. Inner join employees with departments:\n"
     ]
    }
   ],
   "source": [
    "print(\"=== JOIN OPERATIONS ===\")\n",
    "\n",
    "print(\"1. Inner join employees with departments:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----------+--------+\n",
      "|   name|salary| department|division|\n",
      "+-------+------+-----------+--------+\n",
      "|  Alice| 75000|Engineering|    Tech|\n",
      "|Charlie| 80000|Engineering|    Tech|\n",
      "|  Frank| 82000|Engineering|    Tech|\n",
      "|  Diana| 70000|  Marketing|Business|\n",
      "|    Bob| 65000|      Sales|Business|\n",
      "|    Eve| 68000|      Sales|Business|\n",
      "+-------+------+-----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT e.name, e.salary, e.department, d.division\n",
    "FROM employees e\n",
    "INNER JOIN departments d ON e.department = d.dept_name\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4c602ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+------+--------+\n",
      "|   name| department|salary|division|\n",
      "+-------+-----------+------+--------+\n",
      "|  Alice|Engineering| 75000|    Tech|\n",
      "|    Bob|      Sales| 65000|Business|\n",
      "|Charlie|Engineering| 80000|    Tech|\n",
      "|  Diana|  Marketing| 70000|Business|\n",
      "|    Eve|      Sales| 68000|Business|\n",
      "|  Frank|Engineering| 82000|    Tech|\n",
      "+-------+-----------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT e.name, e.department, e.salary, d.division\n",
    "    FROM employees e\n",
    "    LEFT JOIN departments d ON e.department = d.dept_name\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "de737b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|      avg(salary)|\n",
      "+-----------------+\n",
      "|73333.33333333333|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT AVG(salary) FROM employees\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b3f23ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|   name|salary|\n",
      "+-------+------+\n",
      "|  Frank| 82000|\n",
      "|Charlie| 80000|\n",
      "|  Alice| 75000|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT name, salary\n",
    "    FROM employees\n",
    "    WHERE salary > (SELECT AVG(salary) FROM employees)\n",
    "    ORDER BY salary DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "245bcbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "| department|avg_salary|\n",
      "+-----------+----------+\n",
      "|Engineering|   79000.0|\n",
      "|      Sales|   66500.0|\n",
      "|  Marketing|   70000.0|\n",
      "+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT department, AVG(salary) as avg_salary\n",
    "        FROM employees\n",
    "        GROUP BY department\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0c891e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "| department|avg_salary|\n",
      "+-----------+----------+\n",
      "|Engineering|   79000.0|\n",
      "+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT department, avg_salary\n",
    "    FROM (\n",
    "        SELECT department, AVG(salary) as avg_salary\n",
    "        FROM employees\n",
    "        GROUP BY department\n",
    "    ) dept_avg\n",
    "    ORDER BY avg_salary DESC\n",
    "    LIMIT 1\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d8cd98f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+------+\n",
      "|   name| department|salary|\n",
      "+-------+-----------+------+\n",
      "|  Alice|Engineering| 75000|\n",
      "|    Bob|      Sales| 65000|\n",
      "|Charlie|Engineering| 80000|\n",
      "|  Diana|  Marketing| 70000|\n",
      "|    Eve|      Sales| 68000|\n",
      "|  Frank|Engineering| 82000|\n",
      "+-------+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT name, department, salary\n",
    "    FROM employees\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "05550969",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/13 18:29:38 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/07/13 18:29:38 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/07/13 18:29:38 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+------+-------------+\n",
      "|   name| department|salary|running_total|\n",
      "+-------+-----------+------+-------------+\n",
      "|    Bob|      Sales| 65000|        65000|\n",
      "|    Eve|      Sales| 68000|       133000|\n",
      "|  Diana|  Marketing| 70000|       203000|\n",
      "|  Alice|Engineering| 75000|       278000|\n",
      "|Charlie|Engineering| 80000|       358000|\n",
      "|  Frank|Engineering| 82000|       440000|\n",
      "+-------+-----------+------+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/13 18:29:38 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/07/13 18:29:38 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT name, department, salary,\n",
    "           SUM(salary) OVER (ORDER BY salary ROWS UNBOUNDED PRECEDING) as running_total\n",
    "    FROM employees\n",
    "    ORDER BY salary\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5e9b93b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "| department|avg_salary|\n",
      "+-----------+----------+\n",
      "|Engineering|   79000.0|\n",
      "|      Sales|   66500.0|\n",
      "|  Marketing|   70000.0|\n",
      "+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "        SELECT department, AVG(salary) as avg_salary\n",
    "        FROM employees\n",
    "        GROUP BY department\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "470c4ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+------+\n",
      "|   name| department|salary|\n",
      "+-------+-----------+------+\n",
      "|  Frank|Engineering| 82000|\n",
      "|Charlie|Engineering| 80000|\n",
      "|    Eve|      Sales| 68000|\n",
      "+-------+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    WITH dept_stats AS (\n",
    "        SELECT department, AVG(salary) as avg_salary\n",
    "        FROM employees\n",
    "        GROUP BY department\n",
    "    ),\n",
    "    top_performers AS (\n",
    "        SELECT e.name, e.department, e.salary\n",
    "        FROM employees e\n",
    "        JOIN dept_stats d ON e.department = d.department\n",
    "        WHERE e.salary > d.avg_salary\n",
    "    )\n",
    "    SELECT * FROM top_performers\n",
    "    ORDER BY salary DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26696a03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "211080cd",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 6. Practice Exercises\n",
    "\n",
    "Complete these SQL exercises to test your understanding.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
