{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ee2eef1",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Pandas Medallion Architecture Learning Guide - Practice\n",
    "\n",
    "Welcome to your Pandas learning repository! This notebook will guide you through the core concepts of data processing using pandas, focusing on the Medallion Architecture (Bronze, Silver, Gold layers). You'll learn how to ingest raw data, transform it, and aggregate it for analytical purposes using pandas - a great foundation before moving to distributed processing with PySpark.\n",
    "\n",
    "## What is the Medallion Architecture?\n",
    "\n",
    "The Medallion Architecture is a data design pattern used to logically organize data in a data lake:\n",
    "- **Bronze Layer**: Raw data as-is from source systems\n",
    "- **Silver Layer**: Cleaned, validated, and enriched data\n",
    "- **Gold Layer**: Business-level aggregations for analytics and reporting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9b2b29",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 1. Setting up your pandas environment\n",
    "\n",
    "Let's start by importing the necessary libraries and checking our environment.\n",
    "\n",
    "**Exercise 1.1**: Import pandas and other necessary libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33672e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import pandas, numpy, os, datetime and other necessary libraries\n",
    "# TODO: Print pandas and numpy versions\n",
    "# TODO: Print current working directory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602a3eef",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2. Bronze Layer: Raw Data Ingestion\n",
    "\n",
    "The Bronze layer is where raw data is ingested as-is from source systems. We'll read the sample sales data from `data/raw/sales_data.csv` and save it to the bronze layer.\n",
    "\n",
    "**Exercise 2.1**: Read the raw CSV file and explore its structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfd378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Read raw data from '../data/raw/sales_data.csv'\n",
    "# TODO: Print schema using dtypes\n",
    "# TODO: Print dataset shape and total records\n",
    "# TODO: Display first 5 rows\n",
    "# TODO: Display basic statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ef134a",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "**Exercise 2.2**: Save the bronze layer data to parquet format for better performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16934ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create bronze directory using os.makedirs\n",
    "# TODO: Save bronze data as parquet file\n",
    "# TODO: Print confirmation message and file size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3851e04",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. Silver Layer: Cleaned and Conformed Data\n",
    "\n",
    "The Silver layer contains cleaned, conformed, and enriched data. We'll perform data quality checks, calculate derived columns, and add metadata.\n",
    "\n",
    "**Exercise 3.1**: Load bronze data and perform data quality checks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d5e016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load bronze data from parquet file\n",
    "# TODO: Check for missing values using isnull().sum()\n",
    "# TODO: Check for duplicate rows\n",
    "# TODO: Print unique values for each column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa4e12b",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "**Exercise 3.2**: Create the silver layer with enrichments and transformations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ea953a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a copy of bronze_df for silver layer\n",
    "# TODO: Convert transaction_date to datetime\n",
    "# TODO: Calculate total_price = quantity * price\n",
    "# TODO: Add processing_timestamp and data_source columns\n",
    "# TODO: Extract date components (year, month, quarter, day_of_week)\n",
    "# TODO: Add business logic columns (price_category, order_size) using pd.cut\n",
    "# TODO: Print schema and display sample data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1608ad35",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "**Exercise 3.3**: Apply data quality filters and save the silver layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0b8ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Print records count before filtering\n",
    "# TODO: Filter out invalid data (quantity > 0, price > 0, total_price > 0)\n",
    "# TODO: Print records count after filtering\n",
    "# TODO: Create silver directory and save filtered data as parquet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8f94d1",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. Gold Layer: Aggregated Data for Analytics\n",
    "\n",
    "The Gold layer is optimized for analytics and reporting. We'll create various aggregations suitable for business intelligence and reporting.\n",
    "\n",
    "**Exercise 4.1**: Create sales summary aggregation by product and city.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cab467c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load silver data from parquet file\n",
    "# TODO: Create gold layer aggregation by grouping by product_name and city\n",
    "# TODO: Aggregate: count transactions, sum/mean total_price, sum/mean quantity\n",
    "# TODO: Flatten column names and reset index\n",
    "# TODO: Print schema and display sample data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb10006",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "**Exercise 4.2**: Perform analytics queries on the Gold table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2a9452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find top 5 products by total revenue (group by product_name)\n",
    "# TODO: Find top 5 cities by total revenue (group by city)\n",
    "# TODO: Find top 10 product-city combinations by revenue\n",
    "# TODO: Create gold directory and save aggregated data as parquet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffd0b10",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5. Summary and Cleanup\n",
    "\n",
    "Let's summarize what we've accomplished in our Medallion Architecture implementation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45b426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Print completion message with pipeline summary\n",
    "# TODO: List files created in each data directory (bronze, silver, gold)\n",
    "# TODO: Print congratulations message and next steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bddbf9f",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that you've mastered the Medallion Architecture with pandas, here are some suggestions for further learning:\n",
    "\n",
    "### Immediate Next Steps:\n",
    "- **Try the PySpark version**: Move to `practice_pyspark_medallion_architecture_guide.ipynb` for distributed processing\n",
    "- **Experiment with different data sources**: JSON, Excel, databases\n",
    "- **Add more complex transformations**: Pivot tables, time series analysis, statistical functions\n",
    "\n",
    "### Advanced Concepts to Explore:\n",
    "- **Data Quality Monitoring**: Implement data validation rules and monitoring\n",
    "- **Incremental Processing**: Handle new data arriving daily/hourly\n",
    "- **Schema Evolution**: Handle changes in data structure over time\n",
    "- **Performance Optimization**: Chunking, parallel processing, memory management\n",
    "\n",
    "### Production Considerations:\n",
    "- **Error Handling**: Robust error handling and logging\n",
    "- **Configuration Management**: External config files for flexibility\n",
    "- **Monitoring and Alerting**: Track pipeline health and performance\n",
    "- **Testing**: Unit tests and data quality tests\n",
    "\n",
    "Happy data engineering! ðŸš€\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
