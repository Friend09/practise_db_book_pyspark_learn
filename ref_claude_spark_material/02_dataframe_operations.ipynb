{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# DataFrame Operations - Practice Notebook\n",
    "\n",
    "This notebook focuses on **Untyped Dataset Operations** (DataFrame operations) as covered in the [Spark SQL Getting Started Guide](https://spark.apache.org/docs/latest/sql-getting-started.html).\n",
    "\n",
    "## Learning Objectives\n",
    "- Master DataFrame transformations and actions\n",
    "- Understand lazy evaluation in Spark\n",
    "- Practice column operations and expressions\n",
    "- Work with different data types and functions\n",
    "\n",
    "## Sections\n",
    "1. **Setup and Data Preparation**\n",
    "2. **Column Selection and Expressions**\n",
    "3. **Filtering and Conditional Operations**\n",
    "4. **Transformations vs Actions**\n",
    "5. **Working with Functions**\n",
    "6. **Practice Exercises**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6155e3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Create SparkSession\n",
    "spark = SparkSession.builder.appName(\"DataFrame Operations\").getOrCreate()\n",
    "\n",
    "# Create sample data for practice\n",
    "data = [\n",
    "    (\"Alice\", 25, \"Engineer\", 75000, \"2020-01-15\"),\n",
    "    (\"Bob\", 30, \"Manager\", 85000, \"2019-03-20\"),\n",
    "    (\"Charlie\", 35, \"Engineer\", 80000, \"2018-06-10\"),\n",
    "    (\"Diana\", 28, \"Analyst\", 65000, \"2021-02-28\"),\n",
    "    (\"Eve\", 32, \"Manager\", 90000, \"2017-11-05\"),\n",
    "    (\"Frank\", 29, \"Engineer\", 78000, \"2020-09-12\")\n",
    "]\n",
    "\n",
    "columns = [\"name\", \"age\", \"job_title\", \"salary\", \"hire_date\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "print(\"Sample DataFrame:\")\n",
    "df.show()\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 1. Column Selection and Expressions\n",
    "\n",
    "Learn different ways to select and manipulate columns in DataFrames.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845c207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different ways to select columns\n",
    "print(\"1. Select single column (string):\")\n",
    "df.select(\"name\").show()\n",
    "\n",
    "print(\"\\n2. Select multiple columns (strings):\")\n",
    "df.select(\"name\", \"age\", \"salary\").show()\n",
    "\n",
    "print(\"\\n3. Select using column objects:\")\n",
    "df.select(df.name, df.age).show()\n",
    "\n",
    "print(\"\\n4. Select using column indexing (recommended):\")\n",
    "df.select(df[\"name\"], df[\"age\"]).show()\n",
    "\n",
    "print(\"\\n5. Select all columns:\")\n",
    "df.select(\"*\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2e931c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column expressions and calculations\n",
    "print(\"6. Mathematical operations:\")\n",
    "df.select(df[\"name\"], df[\"salary\"], (df[\"salary\"] * 0.1).alias(\"bonus\")).show()\n",
    "\n",
    "print(\"\\n7. String operations:\")\n",
    "df.select(df[\"name\"], F.upper(df[\"name\"]).alias(\"name_upper\")).show()\n",
    "\n",
    "print(\"\\n8. Multiple expressions:\")\n",
    "df.select(\n",
    "    df[\"name\"],\n",
    "    df[\"age\"],\n",
    "    (df[\"age\"] + 5).alias(\"age_in_5_years\"),\n",
    "    (df[\"salary\"] / 12).alias(\"monthly_salary\")\n",
    ").show()\n",
    "\n",
    "print(\"\\n9. Conditional expressions:\")\n",
    "df.select(\n",
    "    df[\"name\"],\n",
    "    df[\"age\"],\n",
    "    F.when(df[\"age\"] >= 30, \"Senior\").otherwise(\"Junior\").alias(\"seniority\")\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2. Filtering and Conditional Operations\n",
    "\n",
    "Practice different filtering techniques and conditional logic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4facdf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic filtering\n",
    "print(\"1. Filter by age:\")\n",
    "df.filter(df[\"age\"] > 30).show()\n",
    "\n",
    "print(\"\\n2. Filter by job title:\")\n",
    "df.filter(df[\"job_title\"] == \"Engineer\").show()\n",
    "\n",
    "print(\"\\n3. Multiple conditions (AND):\")\n",
    "df.filter((df[\"age\"] > 28) & (df[\"salary\"] > 75000)).show()\n",
    "\n",
    "print(\"\\n4. Multiple conditions (OR):\")\n",
    "df.filter((df[\"job_title\"] == \"Manager\") | (df[\"salary\"] > 85000)).show()\n",
    "\n",
    "print(\"\\n5. String contains:\")\n",
    "df.filter(df[\"name\"].contains(\"a\")).show()\n",
    "\n",
    "print(\"\\n6. IN operator:\")\n",
    "df.filter(df[\"job_title\"].isin([\"Engineer\", \"Manager\"])).show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. Transformations vs Actions\n",
    "\n",
    "Understanding the difference between lazy transformations and actions that trigger execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a32982c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations (lazy - don't execute immediately)\n",
    "print(\"=== TRANSFORMATIONS (Lazy) ===\")\n",
    "print(\"These operations don't execute until an action is called\")\n",
    "\n",
    "# Create a series of transformations\n",
    "filtered_df = df.filter(df[\"age\"] > 25)\n",
    "selected_df = filtered_df.select(\"name\", \"age\", \"salary\")\n",
    "sorted_df = selected_df.orderBy(\"salary\", ascending=False)\n",
    "\n",
    "print(\"Transformations created, but not executed yet...\")\n",
    "print(\"Type of result:\", type(sorted_df))\n",
    "\n",
    "# Actions (eager - trigger execution)\n",
    "print(\"\\n=== ACTIONS (Eager) ===\")\n",
    "print(\"These operations trigger execution of all transformations\")\n",
    "\n",
    "print(\"\\n1. show() - Display data:\")\n",
    "sorted_df.show()\n",
    "\n",
    "print(\"\\n2. count() - Count rows:\")\n",
    "print(f\"Number of rows: {sorted_df.count()}\")\n",
    "\n",
    "print(\"\\n3. collect() - Collect all data to driver:\")\n",
    "collected_data = sorted_df.collect()\n",
    "print(f\"Collected data type: {type(collected_data)}\")\n",
    "print(f\"First row: {collected_data[0]}\")\n",
    "\n",
    "print(\"\\n4. first() - Get first row:\")\n",
    "first_row = sorted_df.first()\n",
    "print(f\"First row: {first_row}\")\n",
    "\n",
    "print(\"\\n5. take(n) - Take first n rows:\")\n",
    "first_two = sorted_df.take(2)\n",
    "print(f\"First two rows: {first_two}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. Working with Built-in Functions\n",
    "\n",
    "Explore Spark's built-in functions for data manipulation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e27f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# String functions\n",
    "print(\"=== STRING FUNCTIONS ===\")\n",
    "df.select(\n",
    "    df[\"name\"],\n",
    "    F.upper(df[\"name\"]).alias(\"name_upper\"),\n",
    "    F.lower(df[\"name\"]).alias(\"name_lower\"),\n",
    "    F.length(df[\"name\"]).alias(\"name_length\"),\n",
    "    F.substring(df[\"name\"], 1, 3).alias(\"first_3_chars\")\n",
    ").show()\n",
    "\n",
    "# Mathematical functions\n",
    "print(\"\\n=== MATHEMATICAL FUNCTIONS ===\")\n",
    "df.select(\n",
    "    df[\"name\"],\n",
    "    df[\"salary\"],\n",
    "    F.round(df[\"salary\"] / 12, 2).alias(\"monthly_salary\"),\n",
    "    F.sqrt(df[\"age\"]).alias(\"sqrt_age\"),\n",
    "    F.abs(df[\"age\"] - 30).alias(\"age_diff_from_30\")\n",
    ").show()\n",
    "\n",
    "# Date functions (convert string to date first)\n",
    "print(\"\\n=== DATE FUNCTIONS ===\")\n",
    "df_with_date = df.withColumn(\"hire_date\", F.to_date(df[\"hire_date\"], \"yyyy-MM-dd\"))\n",
    "\n",
    "df_with_date.select(\n",
    "    df[\"name\"],\n",
    "    df_with_date[\"hire_date\"],\n",
    "    F.year(df_with_date[\"hire_date\"]).alias(\"hire_year\"),\n",
    "    F.month(df_with_date[\"hire_date\"]).alias(\"hire_month\"),\n",
    "    F.datediff(F.current_date(), df_with_date[\"hire_date\"]).alias(\"days_since_hire\")\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5. Advanced DataFrame Operations\n",
    "\n",
    "Explore more advanced operations like grouping, aggregations, and window functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4bc70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping and aggregation\n",
    "print(\"=== GROUPING AND AGGREGATION ===\")\n",
    "print(\"1. Group by job title and calculate statistics:\")\n",
    "df.groupBy(\"job_title\").agg(\n",
    "    F.count(\"*\").alias(\"count\"),\n",
    "    F.avg(\"salary\").alias(\"avg_salary\"),\n",
    "    F.min(\"age\").alias(\"min_age\"),\n",
    "    F.max(\"age\").alias(\"max_age\")\n",
    ").show()\n",
    "\n",
    "print(\"\\n2. Multiple grouping columns:\")\n",
    "df.withColumn(\"age_group\", F.when(df[\"age\"] < 30, \"Young\").otherwise(\"Experienced\")) \\\n",
    "  .groupBy(\"job_title\", \"age_group\") \\\n",
    "  .agg(F.count(\"*\").alias(\"count\"), F.avg(\"salary\").alias(\"avg_salary\")) \\\n",
    "  .show()\n",
    "\n",
    "# Window functions\n",
    "print(\"\\n=== WINDOW FUNCTIONS ===\")\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Define window specifications\n",
    "window_spec = Window.partitionBy(\"job_title\").orderBy(\"salary\")\n",
    "window_all = Window.orderBy(\"salary\")\n",
    "\n",
    "df.select(\n",
    "    df[\"name\"],\n",
    "    df[\"job_title\"],\n",
    "    df[\"salary\"],\n",
    "    F.row_number().over(window_spec).alias(\"rank_in_job\"),\n",
    "    F.rank().over(window_all).alias(\"overall_rank\"),\n",
    "    F.lag(df[\"salary\"], 1).over(window_all).alias(\"prev_salary\")\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 6. Practice Exercises\n",
    "\n",
    "Complete these exercises to test your understanding of DataFrame operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ba94f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Create a new DataFrame with sales data\n",
    "sales_data = [\n",
    "    (\"Product A\", \"Electronics\", 1500, 10),\n",
    "    (\"Product B\", \"Clothing\", 800, 25),\n",
    "    (\"Product C\", \"Electronics\", 2000, 5),\n",
    "    (\"Product D\", \"Books\", 300, 50),\n",
    "    (\"Product E\", \"Clothing\", 1200, 15),\n",
    "    (\"Product F\", \"Electronics\", 1800, 8)\n",
    "]\n",
    "\n",
    "sales_df = spark.createDataFrame(sales_data, [\"product_name\", \"category\", \"price\", \"quantity\"])\n",
    "sales_df.show()\n",
    "\n",
    "# TODO: Complete the following exercises using the sales_df\n",
    "\n",
    "print(\"Exercise 1: Select product_name and calculate total_value (price * quantity)\")\n",
    "# Your code here\n",
    "\n",
    "print(\"\\nExercise 2: Filter products with price > 1000\")\n",
    "# Your code here\n",
    "\n",
    "print(\"\\nExercise 3: Add a price_category column: 'Expensive' if price > 1500, else 'Affordable'\")\n",
    "# Your code here\n",
    "\n",
    "print(\"\\nExercise 4: Group by category and calculate average price and total quantity\")\n",
    "# Your code here\n",
    "\n",
    "print(\"\\nExercise 5: Find the most expensive product in each category\")\n",
    "# Your code here\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
